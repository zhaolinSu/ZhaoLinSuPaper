\relax 
\citation{ERDEM2006156}
\citation{1192765}
\citation{1315006}
\citation{}
\citation{ERDEM2006156}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Works}{1}}
\newlabel{sec:rw}{{II}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Multi Cameras System}{1}}
\citation{NIPS2015_5638}
\citation{yolov3}
\citation{NIPS2015_5638}
\citation{yolov3}
\citation{7961803}
\citation{Li_2015_CVPR}
\citation{Yang_2016_CVPR}
\citation{NIPS2015_5638}
\citation{10.1007/978-3-319-10602-1_26}
\citation{Gordon_2018_CVPR}
\citation{Ehsani_2018_CVPR}
\citation{Vondrick_2016_CVPR}
\citation{GREWAL20171}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Computer vision}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces YOLOv3 is more suitable in state-of-the-art models.}}{2}}
\newlabel{fig}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Weight sensor}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}official tones}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-E}}end-user comments}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Method}{2}}
\citation{Ball88}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architecture of our simulated scenarios}}{3}}
\newlabel{fig}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Multi cameras and Build scene}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces H-FOV and V-FOV .}}{3}}
\newlabel{fig}{{3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The field of view of lens is related to focal length, f is the focal length, h is the horizontal dimension of the sensor.}}{3}}
\newlabel{fig}{{4}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Cameras Selected}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces DPI and PPI}}{3}}
\newlabel{fig}{{5}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Scope of sight of 360бу version camera}}{4}}
\newlabel{fig}{{6}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Scope of sight of 180бу version camera}}{4}}
\newlabel{fig}{{7}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Item Recognition}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Simulator}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Scene simulation}{4}}
\citation{199317}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The whole simulated supermarket scene}}{5}}
\newlabel{fig}{{8}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Information on the shelf captured by camera shuttle}}{5}}
\newlabel{fig}{{9}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Item Recognition}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The test set image what we use in our experiment}}{5}}
\newlabel{fig}{{10}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Put the "nutella" pictures into our recognition system and recognize the information.}}{5}}
\newlabel{fig}{{11}{5}}
\bibstyle{IEEEtran}
\bibdata{refer_output}
\bibcite{ERDEM2006156}{1}
\bibcite{1192765}{2}
\bibcite{NIPS2015_5638}{3}
\bibcite{yolov3}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Through our survey, the supermarkets whether can use our identification system}}{6}}
\newlabel{fig}{{12}{6}}
\@writefile{toc}{\contentsline {section}{References}{6}}
