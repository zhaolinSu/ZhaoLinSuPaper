@article{yolov3,
  title={YOLOv3: An Incremental Improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal = {arXiv},
  year={2018}
}

@article{ERDEM2006156,
title = "Automated camera layout to satisfy task-specific and floor plan-specific coverage requirements",
journal = "Computer Vision and Image Understanding",
volume = "103",
number = "3",
pages = "156 - 169",
year = "2006",
note = "Special issue on Omnidirectional Vision and Camera Networks",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2006.06.005",
url = "http://www.sciencedirect.com/science/article/pii/S1077314206000671",
author = "U?ur Murat Erdem and Stan Sclaroff",
keywords = "Camera placement, Sensor networks, Visibility, Best view",
abstract = "In many multi-camera vision systems the effect of camera locations on the task-specific quality of service is ignored. Researchers in Computational Geometry have proposed elegant solutions for some sensor location problem classes. Unfortunately, these solutions use unrealistic assumptions about the cameras¡¯ capabilities that make these algorithms unsuitable for many real world computer vision applications. In this paper, the general camera placement problem is first defined with assumptions that are more consistent with the capabilities of real world cameras. The region to be observed by cameras may be volumetric, static or dynamic, and may include holes. A subclass of this general problem can be formulated in terms of planar regions that are typical of building floor plans. Given a floor plan to be observed, the problem is then to reliably compute a camera layout such that certain task-specific constraints are met. A solution to this problem is obtained via binary optimization over a discrete problem space. In experiments the performance of the resulting system is demonstrated with different real indoor and outdoor floor plans."
}

@INPROCEEDINGS{1192765,
author={L. M. Ni and Yunhao Liu and Yiu Cho Lau and A. P. Patil},
booktitle={Proceedings of the First IEEE International Conference on Pervasive Computing and Communications, 2003. (PerCom 2003).},
title={LANDMARC: indoor location sensing using active RFID},
year={2003},
volume={},
number={},
pages={407-415},
keywords={identification technology;indoor radio;radio direction-finding;LANDMARC;indoor location sensing;active RFID;mobile computing devices;embedded technology;context-aware applications;location sensing prototype system;reference tags;Radiofrequency identification;Active RFID tags;Prototypes;Global Positioning System;Computer science;Mobile computing;Wireless sensor networks;Radio frequency;Radar tracking;Embedded computing},
doi={10.1109/PERCOM.2003.1192765},
ISSN={},
month={March},}

@INPROCEEDINGS{1221002,
author={F. Porikli and A. Divakaran},
booktitle={2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)},
title={Multi-camera calibration, object tracking and query generation},
year={2003},
volume={1},
number={},
pages={I-653},
keywords={calibration;object detection;image sequences;image representation;image colour analysis;large-scale systems;belief networks;video signal processing;video cameras;query generation;multicamera calibration;video summarization method;automatic object tracking;video sequences;object-based representation;intercamera color calibration problem;large-scale systems;mean-shift analysis;Bayesian belief network;Calibration;Cameras;Radiometry;Object oriented modeling;Bayesian methods;Surveillance;Costs;Video sequences;Large-scale systems;Object detection},
doi={10.1109/ICME.2003.1221002},
ISSN={},
month={July},}

@incollection{NIPS2015_5638,
title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {91--99},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf}
}

@article{Ball88,
author = {Karlene K. Ball and Bettina L. Beard and Daniel L. Roenker and Richard L. Miller and David S. Griggs},
journal = {J. Opt. Soc. Am. A},
keywords = {Color; Continuous variables; Eye movements; Feature extraction; Peripheral vision; Saccades},
number = {12},
pages = {2210--2219},
publisher = {OSA},
title = {Age and visual search: expanding the useful field of view},
volume = {5},
month = {Dec},
year = {1988},
url = {http://josaa.osa.org/abstract.cfm?URI=josaa-5-12-2210},
doi = {10.1364/JOSAA.5.002210},
abstract = {The useful field of view is defined as the visual area in which information can be acquired within one eye fixation. We studied visual search within this context and found a reduction in the size of the field as a function of age. This loss, however, was recovered partially with practice. Standard acuity and perimetric tests of visual field, although diagnostic of disease, underestimate the degree of difficulty experienced by visually healthy older adults in everyday activities requiring the use of peripheral vision. To aid in predicting such performance, a model incorporating the effects of distractors and secondary task demands was developed.},
}

@INPROCEEDINGS{1315006,
author={V. {Vaish} and B. {Wilburn} and N. {Joshi} and M. {Levoy}},
booktitle={Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
title={Using plane + parallax for calibrating dense camera arrays},
year={2004},
volume={1},
number={},
pages={I-I},
keywords={cameras;calibration;rendering (computer graphics);photography;image processing;computational geometry;plane-parallax framework;metric calibration;dense camera arrays;light field images;computer graphics;image based rendering;synthetic aperture photography;shape recovery;camera position estimation;affine coordinate system;geometry;Cameras;Layout;Rendering (computer graphics);Calibration;Geometry;Application software;Computer vision;Lenses;Focusing;Computer graphics},
doi={10.1109/CVPR.2004.1315006},
ISSN={1063-6919},
month={June},}

@INPROCEEDINGS{7961803,
author={H. {Jiang} and E. {Learned-Miller}},
booktitle={2017 12th IEEE International Conference on Automatic Face Gesture Recognition (FG 2017)},
title={Face Detection with the Faster R-CNN},
year={2017},
volume={},
number={},
pages={650-657},
keywords={face recognition;learning (artificial intelligence);object detection;face detection;deep learning-based methods;generic object detection;faster R-CNN;large-scale WIDER face dataset;FDDB;IJB-A;Face detection;Proposals;Face;Object detection;Feature extraction;Benchmark testing;Training},
doi={10.1109/FG.2017.82},
ISSN={},
month={May},}

@InProceedings{Li_2015_CVPR,
author = {Li, Haoxiang and Lin, Zhe and Shen, Xiaohui and Brandt, Jonathan and Hua, Gang},
title = {A Convolutional Neural Network Cascade for Face Detection},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@incollection{NIPS2015_5638,
title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {91--99},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf}
}

@InProceedings{Yang_2016_CVPR,
author = {Yang, Shuo and Luo, Ping and Loy, Chen-Change and Tang, Xiaoou},
title = {WIDER FACE: A Face Detection Benchmark},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@InProceedings{10.1007/978-3-319-10602-1_26,
author="Zitnick, C. Lawrence
and Doll{\'a}r, Piotr",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Edge Boxes: Locating Object Proposals from Edges",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="391--405",
abstract="The use of object proposals is an effective recent approach for increasing the computational efficiency of object detection. We propose a novel method for generating object bounding box proposals using edges. Edges provide a sparse yet informative representation of an image. Our main observation is that the number of contours that are wholly contained in a bounding box is indicative of the likelihood of the box containing an object. We propose a simple box objectness score that measures the number of edges that exist in the box minus those that are members of contours that overlap the box's boundary. Using efficient data structures, millions of candidate boxes can be evaluated in a fraction of a second, returning a ranked set of a few thousand top-scoring proposals. Using standard metrics, we show results that are significantly more accurate than the current state-of-the-art while being faster to compute. In particular, given just 1000 proposals we achieve over 96{\%} object recall at overlap threshold of 0.5 and over 75{\%} recall at the more challenging overlap of 0.7. Our approach runs in 0.25 seconds and we additionally demonstrate a near real-time variant with only minor loss in accuracy.",
isbn="978-3-319-10602-1"
}

@InProceedings{Gordon_2018_CVPR,
author = {Gordon, Daniel and Kembhavi, Aniruddha and Rastegari, Mohammad and Redmon, Joseph and Fox, Dieter and Farhadi, Ali},
title = {IQA: Visual Question Answering in Interactive Environments},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Ehsani_2018_CVPR,
author = {Ehsani, Kiana and Bagherinezhad, Hessam and Redmon, Joseph and Mottaghi, Roozbeh and Farhadi, Ali},
title = {Who Let the Dogs Out? Modeling Dog Behavior From Visual Data},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Vondrick_2016_CVPR,
author = {Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
title = {Anticipating Visual Representations From Unlabeled Video},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}
